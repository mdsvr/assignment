{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c9ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=25.61s)\n",
      "creating index...\n",
      "index created!\n",
      "Training images: 118287\n",
      "Actual images: 118287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "\n",
    "# Define relative paths\n",
    "data_root = 'dataset'\n",
    "train_img_dir = r'D:\\Object Detection Model Building\\dataset\\train2017'\n",
    "train_ann_file = r'D:\\Object Detection Model Building\\dataset\\annotations\\instances_train2017.json'\n",
    "\n",
    "# Verify training set\n",
    "coco = COCO(train_ann_file)\n",
    "print(f'Training images: {len(coco.imgs)}')\n",
    "print(f'Actual images: {len(os.listdir(train_img_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79ffd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=25.96s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Training batches: 14786\n",
      "Validation batches: 625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from coco_dataset import COCODataset, get_transform\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define validation paths\n",
    "val_img_dir = r'D:\\Object Detection Model Building\\dataset\\val2017'\n",
    "val_ann_file = r'D:\\Object Detection Model Building\\dataset\\annotations\\instances_val2017.json'\n",
    "# Create datasets\n",
    "train_dataset = COCODataset(\n",
    "    root=train_img_dir,\n",
    "    annFile=train_ann_file,\n",
    "    transforms=get_transform(train=True)\n",
    ")\n",
    "val_dataset = COCODataset(\n",
    "    root=val_img_dir,\n",
    "    annFile=val_ann_file,\n",
    "    transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows compatibility\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a6796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img_dir: D:\\Object Detection Model Building\\dataset\\train2017\n",
      "train_ann_file: D:\\Object Detection Model Building\\dataset\\annotations\\instances_train2017.json\n",
      "val_img_dir: D:\\Object Detection Model Building\\dataset\\val2017\n",
      "val_ann_file: D:\\Object Detection Model Building\\dataset\\annotations\\instances_val2017.json\n",
      "Training annotations exist: True\n",
      "Validation annotations exist: True\n",
      "loading annotations into memory...\n",
      "Done (t=19.58s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Training batches: 14786\n",
      "Validation batches: 625\n"
     ]
    }
   ],
   "source": [
    "from coco_dataset import COCODataset, get_transform\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Define paths for training (absolute)\n",
    "train_img_dir = r'D:\\Object Detection Model Building\\dataset\\train2017'\n",
    "train_ann_file = r'D:\\Object Detection Model Building\\dataset\\annotations\\instances_train2017.json'\n",
    "\n",
    "# Define paths for validation (absolute, as provided)\n",
    "val_img_dir = r'D:\\Object Detection Model Building\\dataset\\val2017'\n",
    "val_ann_file = r'D:\\Object Detection Model Building\\dataset\\annotations\\instances_val2017.json'\n",
    "\n",
    "# Debug: Print paths to confirm correctness\n",
    "print(f\"train_img_dir: {train_img_dir}\")\n",
    "print(f\"train_ann_file: {train_ann_file}\")\n",
    "print(f\"val_img_dir: {val_img_dir}\")\n",
    "print(f\"val_ann_file: {val_ann_file}\")\n",
    "\n",
    "# Verify files exist\n",
    "print(f\"Training annotations exist: {os.path.exists(train_ann_file)}\")\n",
    "print(f\"Validation annotations exist: {os.path.exists(val_ann_file)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = COCODataset(\n",
    "    root=train_img_dir,\n",
    "    annFile=train_ann_file,\n",
    "    transforms=get_transform(train=True)\n",
    ")\n",
    "val_dataset = COCODataset(\n",
    "    root=val_img_dir,\n",
    "    annFile=val_ann_file,\n",
    "    transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows compatibility\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
